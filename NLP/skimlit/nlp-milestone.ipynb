{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-Milestone\n",
    "many-to-one task : \n",
    "- long sentences -> Objective of sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data : [PubMed200k RCT](https://github.com/Franck-Dernoncourt/pubmed-rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with 20k dataset with replace number by @ sign\n",
    "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign'\n",
    "filepath = [ os.path.join(data_dir, file) for file in os.listdir(data_dir) ]\n",
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['###24293578\\n', 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n', 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n', 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n', 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n']\n"
     ]
    }
   ],
   "source": [
    "# read in all line of target text file\n",
    "def get_lines(filepath):\n",
    "    '''\n",
    "    Read text file and return the lines as a list.\n",
    "    '''\n",
    "    with open(filepath, 'r') as file :\n",
    "        return file.readlines()\n",
    "\n",
    "\n",
    "train_lines = get_lines(filepath[2])\n",
    "print(train_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[{'line_number' : 0 ,\n",
    "   'target' : 'OBJECTIVE',\n",
    "   'text' : 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .'\n",
    "   'total_lines' : 5}, # total lines in each Abstract\n",
    "   {''line_number' : 1, \n",
    "   .....\n",
    "}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(filepath):\n",
    "    '''\n",
    "    change long lines to this format\n",
    "    [{'line_number' : 0 ,\n",
    "    'target' : 'OBJECTIVE',\n",
    "    'text' : 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in \n",
    "              improving pain , mobility , and systemic low-grade inflammation in the short term \n",
    "              and whether the effect would be sustained at @ weeks in older adults with moderate \n",
    "              to severe knee osteoarthritis ( OA ) .'\n",
    "    'total_lines' : 5}, # total lines in each Abstract\n",
    "    {''line_number' : 1, \n",
    "    .....\n",
    "    }]\n",
    "    '''\n",
    "    input_lines = get_lines(filepath)\n",
    "    abstract_lines = '' # to save 1 abstract \n",
    "    abstract_samples = []\n",
    "\n",
    "    for line in input_lines :\n",
    "        if line.startswith('###') : #heading of each Abstract\n",
    "            abstract_id = line \n",
    "            abstract_lines = '' # reset old Abstract\n",
    "        elif line.isspace(): # if a new line (last abstract has space)\n",
    "            abstract_split = abstract_lines.splitlines() # split Abstract into seperate line\n",
    "\n",
    "            # loop for content in each Abstract\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_split) :\n",
    "                line_data = {} # for each target and text\n",
    "                target_text = abstract_line.split('\\t') # target and text\n",
    "                line_data['line_number'] = abstract_line_number\n",
    "                line_data['target'] = target_text[0]\n",
    "                line_data['text'] = target_text[1].lower()\n",
    "                line_data['total_lines'] = len(abstract_split) - 1 # start from zero\n",
    "                abstract_samples.append(line_data) # add to list\n",
    "\n",
    "        # content for each abtract\n",
    "        else :\n",
    "            abstract_lines += line\n",
    "\n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'line_number': 9,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'total_lines': 11},\n",
       " {'line_number': 10,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'total_lines': 11},\n",
       " {'line_number': 11,\n",
       "  'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'total_lines': 11},\n",
       " {'line_number': 0,\n",
       "  'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = preprocess_text(filepath[2])\n",
    "val_samples = preprocess_text(filepath[0])\n",
    "test_samples = preprocess_text(filepath[1])\n",
    "train_samples[9:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_number</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line_number       target  \\\n",
       "0             0    OBJECTIVE   \n",
       "1             1      METHODS   \n",
       "2             2      METHODS   \n",
       "3             3      METHODS   \n",
       "4             4      METHODS   \n",
       "5             5      METHODS   \n",
       "6             6      RESULTS   \n",
       "7             7      RESULTS   \n",
       "8             8      RESULTS   \n",
       "9             9      RESULTS   \n",
       "10           10      RESULTS   \n",
       "11           11  CONCLUSIONS   \n",
       "12            0   BACKGROUND   \n",
       "13            1   BACKGROUND   \n",
       "\n",
       "                                                 text  total_lines  \n",
       "0   to investigate the efficacy of @ weeks of dail...           11  \n",
       "1   a total of @ patients with primary knee oa wer...           11  \n",
       "2   outcome measures included pain reduction and i...           11  \n",
       "3   pain was assessed using the visual analog pain...           11  \n",
       "4   secondary outcome measures included the wester...           11  \n",
       "5   serum levels of interleukin @ ( il-@ ) , il-@ ...           11  \n",
       "6   there was a clinically relevant reduction in t...           11  \n",
       "7   the mean difference between treatment arms ( @...           11  \n",
       "8   further , there was a clinically relevant redu...           11  \n",
       "9   these differences remained significant at @ we...           11  \n",
       "10  the outcome measures in rheumatology clinical ...           11  \n",
       "11  low-dose oral prednisolone had both a short-te...           11  \n",
       "12  emotional eating is associated with overeating...           10  \n",
       "13  yet , empirical evidence for individual ( trai...           10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature of data\n",
    "train_sentences = train_df['text'].to_list()\n",
    "val_sentences = val_df['text'].to_list()\n",
    "test_sentences = test_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]] (180040, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder # or LabelEncoder(1D data)return a number for each class\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False) # to compatible with Tensorflow\n",
    "train_labels = onehot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
    "val_labels = onehot_encoder.transform(val_df['target'].to_numpy().reshape(-1,1))\n",
    "test_labels = onehot_encoder.transform(test_df['target'].to_numpy().reshape(-1,1))\n",
    "print(train_labels[:5], train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 2 2] (180040,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_ = label_encoder.fit_transform(train_df['target'])\n",
    "val_labels_ = label_encoder.transform(val_df['target'])\n",
    "test_labels_ = label_encoder.transform(test_df['target'])\n",
    "print(train_labels_[:5], train_labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS']\n",
      "['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS']\n"
     ]
    }
   ],
   "source": [
    "class_name = label_encoder.classes_\n",
    "print(onehot_encoder.categories_[0])\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluation function\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_score(y_true, y_preds):\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision, recall, f1_score = precision_recall_fscore_support(y_true, y_preds, average='weighted')[:-1]\n",
    "    evaluation_dict = {'accuracy':accuracy,'precision':precision,'recall':recall,'f1_score':f1_score}\n",
    "    return evaluation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline : Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0 = Pipeline([ \n",
    "    ('tf-idf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences, train_labels_) # naive bayes handle 1D targer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> if using onehot_encoder : ```ValueError: y should be a 1d array, got an array of shape (180040, 5) instead.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7218323844829869,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1_score': 0.6989250353450294}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction \n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_score = evaluate_score(val_labels_, baseline_preds)\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep sequence models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "#how long is each sentence on average ?\n",
    "sentences_lens = [len(sentences.split()) for sentences in train_sentences] \n",
    "avg_sentences = np.mean(sentences_lens)\n",
    "avg_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sentences_lens, bins=30)\n",
    "plt.title('len of each sentences')\n",
    "plt.xlim([0, 120]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seg_len = int(np.percentile(sentences_lens, 95)) # 95% percentile (make sure don't cut many information off)\n",
    "output_seg_len # just missed 5% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_vectorizer: text to number (like ordinal encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text vectorizer layer (text to number)\n",
    "max_vocab = 68000 # from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab, \n",
    "                             output_sequence_length=output_seg_len)\n",
    "\n",
    "#adapt to training data\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "secondary outcomes will include monthly clinic visits , provision of lifestyle advice , use of antihypertensive medications and use of aspirin .\n",
      "\n",
      "Length of text: 144\n",
      "Vectorized:\n",
      "[ 151   75   95  637 1097  859  620 2191    4  839 1589   87    4 2889\n",
      " 1098    3   87    4 1271    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "#test out text_vectorizer\n",
    "import random\n",
    "sample = random.choice(train_sentences)\n",
    "print(f'Text:\\n{sample}\\n')\n",
    "print(f'Length of text: {len(sample)}')\n",
    "print(f'Vectorized:\\n{text_vectorizer(sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocab : 64841\n",
      "Most common word : ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']\n",
      "Least common word : ['aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# how many word in training\n",
    "vocab_list = text_vectorizer.get_vocabulary()\n",
    "length_vocab = len(vocab_list)\n",
    "print('Number of vocab :',length_vocab)\n",
    "print('Most common word :',vocab_list[:10])\n",
    "print('Least common word :',vocab_list[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding: (relavent number word by word, randomize number first and train like weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=length_vocab, \n",
    "                               output_dim=128, # dimetion of output\n",
    "                               mask_zero= True, # will do more efficient computing (when a lot of zero in matrix)\n",
    "                               name='token_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : secondary outcomes will include monthly clinic visits , provision of lifestyle advice , use of antihypertensive medications and use of aspirin .\n",
      "Vectorized:\n",
      "[[ 151   75   95  637 1097  859  620 2191    4  839 1589   87    4 2889\n",
      "  1098    3   87    4 1271    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      " shape : (1, 55)\n",
      "\n",
      "Embedded:\n",
      "[[-0.0357766   0.03960489 -0.00365805  0.01212858  0.02534685  0.02814177]\n",
      " [-0.00933223  0.03839954  0.04976356  0.04395633 -0.01316857 -0.017798  ]\n",
      " [-0.00492414  0.01663733  0.03320781 -0.02206324  0.00894047  0.00964206]\n",
      " [-0.04341823  0.04353614  0.02993505  0.02088311 -0.03778863 -0.01267475]\n",
      " [-0.03559492  0.04282511 -0.02591112  0.03565272 -0.03570473  0.04577294]]\n",
      " shape : (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "#show example embeding\n",
    "print(f'Text : {sample}')\n",
    "vec_sample = text_vectorizer([sample])\n",
    "print(f'Vectorized:\\n{vec_sample}')\n",
    "print(f' shape : {vec_sample.shape}\\n')\n",
    "em_sample = token_embed(vec_sample)\n",
    "print(f'Embedded:\\n{em_sample[0,:5,:6]}')\n",
    "print(f' shape : {em_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Create datasets : making more efficient to load and train model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn out data into Tensorflow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making more efficien to load and train model\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # auto prefetch many as you can\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # auto prefetch many as you can\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # auto prefetch many as you can\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : ConV1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 32)            20512     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,320,325\n",
      "Trainable params: 8,320,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "562/562 [==============================] - 65s 113ms/step - loss: 0.9537 - accuracy: 0.6276 - val_loss: 0.6975 - val_accuracy: 0.7334\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 58s 104ms/step - loss: 0.6679 - accuracy: 0.7519 - val_loss: 0.6366 - val_accuracy: 0.7683\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 59s 106ms/step - loss: 0.6263 - accuracy: 0.7695 - val_loss: 0.6052 - val_accuracy: 0.7826\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 60s 107ms/step - loss: 0.5983 - accuracy: 0.7838 - val_loss: 0.5876 - val_accuracy: 0.7816\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 59s 105ms/step - loss: 0.5982 - accuracy: 0.7888 - val_loss: 0.5677 - val_accuracy: 0.7942\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vector = text_vectorizer(inputs)\n",
    "token_embeder = token_embed(text_vector)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(token_embeder)\n",
    "x = layers.GlobalAveragePooling1D()(x) \n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "model_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "hist_1 = model_1.fit(train_dataset, \n",
    "                     validation_data=val_dataset, \n",
    "                     steps_per_epoch=int(len(train_dataset) *.1),\n",
    "                     validation_steps = int(len(val_dataset) *.1),\n",
    "                     epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 3 2 2], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "model_1_proba = model_1.predict(val_dataset)\n",
    "model_1_preds = tf.argmax(model_1_proba, axis=1)\n",
    "print(model_1_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7982920693764067,\n",
       " 'precision': 0.797458591333494,\n",
       " 'recall': 0.7982920693764067,\n",
       " 'f1_score': 0.7952949209889866}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_result = evaluate_score(val_labels_, model_1_preds)\n",
    "model_1_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : Feature extraction\n",
    "check : [Universal sentences encoder (USE)](https://tfhub.dev/google/universal-sentence-encoder/4)\n",
    "\n",
    "embedding layers learned from many sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed_hub_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', \n",
    "                                  trainable=False, name='USE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary outcomes will include monthly clinic visits , provision of lifestyle advice , use of antihypertensive medications and use of aspirin .\n"
     ]
    }
   ],
   "source": [
    "#test on sentence\n",
    "print(f'text : {sample}')\n",
    "sample_embed = embed_hub_layer([sample])\n",
    "print(f'embeded :\\n{sample_embed}\\n{sample_embed.shape}') #512 long feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling with USE\n",
    "inputs = layers.Input(shape=[], dtype='string') # [] = any amount of sentences\n",
    "pretrained_embed = embed_hub_layer(inputs) # tokenize text to 512 long vector\n",
    "x = layers.Dense(128, activation='relu')(pretrained_embed)\n",
    "# can add more layer if you want\n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_2.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "hist_2 = model_2.fit(train_dataset, \n",
    "                     validation_data=val_dataset, \n",
    "                     steps_per_epoch=int(len(train_dataset) *.1),\n",
    "                     validation_steps = int(len(val_dataset) *.1),\n",
    "                     epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 : Conv1D with Character embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/M-Kumar-2/publication/321503621/figure/fig2/AS:594531682635776@1518758807406/Character-based-embedding-methodology.png\"  width=500px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make function into character\n",
    "def split_char(sentence):\n",
    "    return ' '.join(list(sentence))\n",
    "\n",
    "split_char(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split sequence-level into character-lavel\n",
    "train_char = [split_char(sentence) for sentence in train_sentences]\n",
    "val_char = [split_char(sentence) for sentence in val_sentences]\n",
    "test_char = [split_char(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what the average charater length\n",
    "char_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_lens = np.mean(char_lens)\n",
    "mean_char_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(char_lens, bins=20)\n",
    "plt.title('character length')\n",
    "#find what character length what cover 95 percentile\n",
    "output_seg_char_len = int(np.percentile(char_lens, 95))\n",
    "plt.axvline(output_seg_char_len, c='black')\n",
    "print(output_seg_char_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all character \n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create char-level token vectorizer\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 # add for space and OOV(UNK)\n",
    "char_vectorize = TextVectorization(max_tokens=NUM_CHAR_TOKENS, output_sequence_length=output_seg_char_len,\n",
    "                                    name='char-vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt to training char\n",
    "char_vectorize.adapt(train_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of char : 28\n",
      "most common char : ['', '[UNK]', 'e', 't', 'i']\n",
      "least common char : ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "#check charactor vocab stat\n",
    "char_vocab = char_vectorize.get_vocabulary()\n",
    "print(f'number of char : {len(char_vocab)}')\n",
    "print(f'most common char : {char_vocab[:5]}')\n",
    "print(f'least common char : {char_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 307\n",
      "m u s c l e   s t r e n g t h   o f   t h e   i r   o r   e r   w a s   n o t   s i g n i f i c a n t l y   d i f f e r e n t   w h e n   c o m p a r i n g   n e u t r a l   @   t o   t h e   m i d - r a n g e   p o s i t i o n   a n d   a t   t h e i r   m o s t   l e n g t h e n e d   p o s i t i o n   .\n",
      "vectorized char : 290\n",
      "[15 16  9 11 12  2  9  3  8  2  6 18  3 13  7 17  3 13  2  4  8  7  8  2\n",
      "  8 20  5  9  6  7  3  9  4 18  6  4 17  4 11  5  6  3 12 19 10  4 17 17\n",
      "  2  8  2  6  3 20 13  2  6 11  7 15 14  5  8  4  6 18  6  2 16  3  8  5\n",
      " 12  3  7  3 13  2 15  4 10  8  5  6 18  2 14  7  9  4  3  4  7  6  5  6\n",
      " 10  5  3  3 13  2  4  8 15  7  9  3 12  2  6 18  3 13  2  6  2 10 14  7\n",
      "  9  4  3  4  7  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n"
     ]
    }
   ],
   "source": [
    "#test char-vectorizer\n",
    "sample = random.choice(train_char)\n",
    "print(f'text : {len(sample)}\\n{sample}')\n",
    "char_vec = char_vectorize([sample])\n",
    "print(f'vectorized char : {len(char_vec[0])}\\n{char_vec[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create char-level embedding\n",
    "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different char\n",
    "                              output_dim=25, # from paper\n",
    "                              mask_zero=True,\n",
    "                              name='char_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char text : 307\n",
      " m u s c l e   s t r e n g t h   o f   t h e   i r   o r   e r   w a s   n o t   s i g n i f i c a n t l y   d i f f e r e n t   w h e n   c o m p a r i n g   n e u t r a l   @   t o   t h e   m i d - r a n g e   p o s i t i o n   a n d   a t   t h e i r   m o s t   l e n g t h e n e d   p o s i t i o n   .\n",
      "char embed : (1, 290, 25)\n",
      " [[ 0.01267979  0.00681015  0.00475659  0.01946977  0.03887084 -0.0087113 ]\n",
      " [-0.02585049 -0.00230441  0.01271143 -0.01810666  0.01599676  0.02551729]\n",
      " [-0.0195442   0.02543082  0.0166275  -0.04790251  0.00860951  0.00175443]\n",
      " [-0.00022705  0.04224862  0.04741519  0.0109699  -0.04907587  0.02327441]\n",
      " [ 0.04948065 -0.02459182 -0.03845556 -0.00143575 -0.01699872  0.00763259]\n",
      " [ 0.01677904 -0.01320298 -0.02205615 -0.02402533  0.01196054 -0.03064685]\n",
      " [-0.0195442   0.02543082  0.0166275  -0.04790251  0.00860951  0.00175443]\n",
      " [ 0.03060381 -0.01089617 -0.03177955  0.01290611 -0.0137828   0.04068179]\n",
      " [ 0.02535054 -0.02835015 -0.02425075 -0.04240865  0.00529666 -0.02334642]\n",
      " [ 0.01677904 -0.01320298 -0.02205615 -0.02402533  0.01196054 -0.03064685]]\n"
     ]
    }
   ],
   "source": [
    "# test our char-embeding layer\n",
    "print(f'char text : {len(sample)}\\n {sample}')\n",
    "char_embed_sample = char_embed(char_vectorize([sample]))\n",
    "print(f'char embed : {char_embed_sample.shape}\\n {char_embed_sample[0,:10,:6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create char-level dataset\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_char, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_char, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_char, test_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " char-vec (TextVectorization  (None, 290)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " char_embed (Embedding)      (None, 290, 25)           700       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 290, 32)           8032      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,897\n",
      "Trainable params: 8,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "562/562 [==============================] - 9s 15ms/step - loss: 1.2658 - accuracy: 0.4746 - val_loss: 1.1260 - val_accuracy: 0.5422\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 1.0931 - accuracy: 0.5522 - val_loss: 1.0272 - val_accuracy: 0.5851\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 1.0233 - accuracy: 0.5895 - val_loss: 0.9640 - val_accuracy: 0.6107\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.9692 - accuracy: 0.6134 - val_loss: 0.9296 - val_accuracy: 0.6283\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 9s 15ms/step - loss: 0.9556 - accuracy: 0.6207 - val_loss: 0.9116 - val_accuracy: 0.6453\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "vectorize_layer = char_vectorize(inputs)\n",
    "embed_layer = char_embed(vectorize_layer)\n",
    "x = layers.Conv1D(filters=32, kernel_size=10, padding='same', activation='relu')(embed_layer)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "model_3 = keras.Model(inputs, outputs)\n",
    "model_3.summary()\n",
    "model_3.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "hist_3 = model_3.fit(train_char_dataset, \n",
    "                     validation_data=val_char_dataset, \n",
    "                     steps_per_epoch=int(len(train_char_dataset) *.1),\n",
    "                     validation_steps = int(len(val_char_dataset) *.1),\n",
    "                     epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 1, 0, 2, 2, 2, 2, 0, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_proba = model_3.predict(val_char_dataset)\n",
    "model_3_preds = tf.argmax(model_3_proba, axis=1)\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6298159671653648,\n",
       " 'precision': 0.6452265048811349,\n",
       " 'recall': 0.6298159671653648,\n",
       " 'f1_score': 0.6250541003715524}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_result = evaluate_score(val_labels_, model_3_preds)\n",
    "model_3_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : 2 inputs from token-embed and char-embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"token_and_char_embedding\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " token_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 55)          0           ['token_input[0][0]']            \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " token_embedding (Embedding)    (None, 55, 128)      8299648     ['text_vectorization[5][0]']     \n",
      "                                                                                                  \n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 55, 64)       32832       ['token_embedding[5][0]']        \n",
      "                                                                                                  \n",
      " char-vec (TextVectorization)   (None, 290)          0           ['char_input[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_3 (Global  (None, 64)          0           ['conv1d_8[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['char-vec[10][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          8320        ['global_max_pooling1d_3[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 48)          9600        ['char_embed[10][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_char_concat (Concatenate  (None, 176)         0           ['dense_12[0][0]',               \n",
      " )                                                                'bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 176)          0           ['token_char_concat[0][0]']      \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          22656       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128)          0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 5)            645         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,374,401\n",
      "Trainable params: 8,374,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# token embedding model\n",
    "token_inputs = layers.Input(shape=(1,), dtype=tf.string, name='token_input')\n",
    "# token_embed_layer = embed_hub_layer(token_inputs) , if using tensorflow hub model\n",
    "text_vector_layer = text_vectorizer(token_inputs)\n",
    "token_embeder_layer = token_embed(text_vector_layer)\n",
    "x = layers.Conv1D(64, 4, padding='same')(token_embeder_layer)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "token_output = layers.Dense(128, activation='relu')(x)\n",
    "token_model = keras.Model(token_inputs, token_output)\n",
    "\n",
    "#char embedding model\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
    "char_vec_layer = char_vectorize(char_inputs)\n",
    "char_embed_layer = char_embed(char_vec_layer)\n",
    "x = layers.Bidirectional(layers.LSTM(24))(char_embed_layer)\n",
    "char_model = keras.Model(char_inputs, x)\n",
    "\n",
    "#concatinate layer\n",
    "token_char_concat = layers.Concatenate(name='token_char_concat')([token_model.output, char_model.output])\n",
    "x = layers.Dropout(.5)(token_char_concat) # prevent overfitting\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(.5)(x)\n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model_4 = keras.Model(inputs=[token_model.input, char_model.input], outputs = outputs, name='token_and_char_embedding')\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#plot hybrid token and char model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# combine token and char to data.Datasets\n",
    "train_token_char_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_char)) # token and char same order as a model\n",
    "train_token_char_labels = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "train_token_char_dataset = tf.data.Dataset.zip((train_token_char_data, train_token_char_labels))\n",
    "train_token_char_dataset = train_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_token_char_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_char))\n",
    "val_token_char_labels = tf.data.Dataset.from_tensor_slices(val_labels)\n",
    "val_token_char_dataset = tf.data.Dataset.zip((val_token_char_data, val_token_char_labels))\n",
    "val_token_char_dataset = val_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_token_char_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_char))\n",
    "test_token_char_labels = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "test_token_char_dataset = tf.data.Dataset.zip((test_token_char_data, test_token_char_labels))\n",
    "test_token_char_dataset = test_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(train_token_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 108s 180ms/step - loss: 0.7119 - accuracy: 0.7400 - val_loss: 0.5617 - val_accuracy: 0.7939\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 100s 179ms/step - loss: 0.5700 - accuracy: 0.7999 - val_loss: 0.5584 - val_accuracy: 0.7926\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 115s 205ms/step - loss: 0.5396 - accuracy: 0.8132 - val_loss: 0.5383 - val_accuracy: 0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2296a0d4b80>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_4.fit(\n",
    "    train_token_char_dataset, \n",
    "    validation_data=val_token_char_dataset, \n",
    "    steps_per_epoch=int(len(train_token_char_dataset) *.1),\n",
    "    validation_steps = int(len(val_token_char_dataset) *.1),\n",
    "    epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 2, 2, 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_proba = model_4.predict(val_token_char_dataset)\n",
    "model_4_preds = tf.argmax(model_4_proba, axis=1)\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8022971004898716,\n",
       " 'precision': 0.805303629098681,\n",
       " 'recall': 0.8022971004898716,\n",
       " 'f1_score': 0.8033949170024978}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_result = evaluate_score(val_labels_, model_4_preds)\n",
    "model_4_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 : token + char + position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_number</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line_number     target                                               text  \\\n",
       "0            0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1            1    METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2            2    METHODS  outcome measures included pain reduction and i...   \n",
       "3            3    METHODS  pain was assessed using the visual analog pain...   \n",
       "4            4    METHODS  secondary outcome measures included the wester...   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['line_number'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['line_number'].plot.hist(bins=10);\n",
    "np.percentile(train_df['line_number'], 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180040, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use tensorflow to one-hot encoder column\n",
    "train_line_numbers_onehot = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)\n",
    "val_line_numbers_onehot = tf.one_hot(val_df['line_number'].to_numpy(), depth=15)\n",
    "test_line_numbers_onehot = tf.one_hot(test_df['line_number'].to_numpy(), depth=15)\n",
    "\n",
    "print(train_line_numbers_onehot.shape)\n",
    "train_line_numbers_onehot[:5,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    24468\n",
       "10    23639\n",
       "12    22113\n",
       "9     19400\n",
       "13    18438\n",
       "14    14610\n",
       "8     12285\n",
       "15    10768\n",
       "7      7464\n",
       "16     7429\n",
       "17     5202\n",
       "6      3353\n",
       "18     3344\n",
       "19     2480\n",
       "20     1281\n",
       "5      1146\n",
       "21      770\n",
       "22      759\n",
       "23      264\n",
       "4       215\n",
       "24      200\n",
       "25      182\n",
       "26       81\n",
       "28       58\n",
       "3        32\n",
       "30       31\n",
       "27       28\n",
       "Name: total_lines, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['total_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['total_lines'].plot.hist(bins=12);\n",
    "np.percentile(train_df['total_lines'], 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180040, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15, 14), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total_lines = tf.one_hot(train_df['total_lines'].to_numpy(), depth=18)\n",
    "val_total_lines = tf.one_hot(val_df['total_lines'].to_numpy(), depth=18)\n",
    "test_total_lines = tf.one_hot(test_df['total_lines'].to_numpy(), depth=18)\n",
    "\n",
    "print(train_total_lines.shape)\n",
    "train_total_lines[:15,:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " token_inputs (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 55)          0           ['token_inputs[0][0]']           \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " token_embedding (Embedding)    (None, 55, 128)      8299648     ['text_vectorization[9][0]']     \n",
      "                                                                                                  \n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 55, 64)       32832       ['token_embedding[9][0]']        \n",
      "                                                                                                  \n",
      " char-vec (TextVectorization)   (None, 290)          0           ['char_input[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_7 (Global  (None, 64)          0           ['conv1d_12[0][0]']              \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['char-vec[14][0]']              \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          8320        ['global_max_pooling1d_7[0][0]'] \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirectional  (None, 48)          9600        ['char_embed[14][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lines_inputs (InputLayer)      [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " total_lines_inputs (InputLayer  [(None, 18)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_char_concat (Concatenate  (None, 176)         0           ['dense_24[0][0]',               \n",
      " )                                                                'bidirectional_8[0][0]']        \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           512         ['lines_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 32)           608         ['total_lines_inputs[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 176)          0           ['token_char_concat[0][0]']      \n",
      "                                                                                                  \n",
      " tribrid_positional (Concatenat  (None, 240)         0           ['dense_25[0][0]',               \n",
      " e)                                                               'dense_26[0][0]',               \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            1205        ['tribrid_positional[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,353,425\n",
      "Trainable params: 8,353,425\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#token embbedding model\n",
    "token_inputs = layers.Input(shape=(1,), dtype=tf.string, name='token_inputs')\n",
    "text_vector_layer = text_vectorizer(token_inputs)\n",
    "token_embeder_layer = token_embed(text_vector_layer)\n",
    "x = layers.Conv1D(64, 4, padding='same')(token_embeder_layer)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "token_output = layers.Dense(128, activation='relu')(x)\n",
    "token_model = keras.Model(token_inputs, token_output)\n",
    "\n",
    "#char embedding model\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
    "char_vec_layer = char_vectorize(char_inputs)\n",
    "char_embed_layer = char_embed(char_vec_layer)\n",
    "x = layers.Bidirectional(layers.LSTM(24))(char_embed_layer)\n",
    "char_model = keras.Model(char_inputs, x)\n",
    "\n",
    "#line number model\n",
    "lines_inputs = layers.Input(shape=(15,),dtype=tf.float32, name='lines_inputs')\n",
    "x = layers.Dense(32, activation='relu')(lines_inputs)\n",
    "lines_model = keras.Model(lines_inputs, x)\n",
    "\n",
    "#total lines model\n",
    "total_lines_inputs = layers.Input(shape=(18,),dtype=tf.float32, name='total_lines_inputs')\n",
    "x = layers.Dense(32, activation='relu')(total_lines_inputs)\n",
    "total_lines_model = keras.Model(total_lines_inputs, x)\n",
    "\n",
    "\n",
    "#concatinate token and char\n",
    "x = layers.Concatenate(name='token_char_concat')([token_model.output, char_model.output ])\n",
    "x = layers.Dropout(.3)(x)\n",
    "\n",
    "#concatinate token_char_concat and lines_model, total_lines_model\n",
    "tribid = layers.Concatenate(name='tribrid_positional')([lines_model.output, total_lines_model.output, x])\n",
    "\n",
    "#create output layer\n",
    "outputs = layers.Dense(5, activation='softmax', name='outputs')(tribid)\n",
    "\n",
    "#model\n",
    "model_5 = keras.Model(inputs=[lines_model.input, \n",
    "                      total_lines_model.input, \n",
    "                      token_model.input, \n",
    "                      char_model.input], \n",
    "                      outputs=outputs)\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=.2),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> label_smoothing : decrease some prediction that are very confident (prevent overfitting). [0, 0, 1, 0, 0] --> [.01, .01, .96, .01, .01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 18), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataset\n",
    "def create_dataset(p1,p2,p3,p4,labels):\n",
    "    train_token_char_pos = tf.data.Dataset.from_tensor_slices((p1, p2, p3, p4))\n",
    "    train_token_char_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((train_token_char_pos, train_token_char_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_token_char_pos_dataset = create_dataset(train_line_numbers_onehot, train_total_lines, train_sentences, train_char, train_labels)\n",
    "val_token_char_pos_dataset = create_dataset(val_line_numbers_onehot, val_total_lines, val_sentences, val_char, val_labels)\n",
    "test_token_char_pos_dataset = create_dataset(test_line_numbers_onehot, test_total_lines, test_sentences, test_char, test_labels)\n",
    "\n",
    "train_token_char_pos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 124s 207ms/step - loss: 0.9736 - accuracy: 0.8164 - val_loss: 0.9208 - val_accuracy: 0.8464\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 105s 186ms/step - loss: 0.8813 - accuracy: 0.8826 - val_loss: 0.9150 - val_accuracy: 0.8418\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 99s 176ms/step - loss: 0.8651 - accuracy: 0.8888 - val_loss: 0.9051 - val_accuracy: 0.8487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x229b32c11e0>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(\n",
    "    train_token_char_pos_dataset,\n",
    "    steps_per_epoch=int(len(train_token_char_pos_dataset)*.1),\n",
    "    validation_data = val_token_char_pos_dataset,\n",
    "    validation_steps=int(len(val_token_char_pos_dataset) *.1),\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 4, 2, 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_proba = model_5.predict(val_token_char_pos_dataset)\n",
    "model_5_preds = tf.argmax(model_5_proba, axis=1)\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8483053091486826,\n",
       " 'precision': 0.8491809348058245,\n",
       " 'recall': 0.8483053091486826,\n",
       " 'f1_score': 0.847231975000299}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_result = evaluate_score(val_labels_, model_5_preds)\n",
    "model_5_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1D-token</th>\n",
       "      <td>0.798292</td>\n",
       "      <td>0.797459</td>\n",
       "      <td>0.798292</td>\n",
       "      <td>0.795295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1D-char</th>\n",
       "      <td>0.629816</td>\n",
       "      <td>0.645227</td>\n",
       "      <td>0.629816</td>\n",
       "      <td>0.625054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token-char</th>\n",
       "      <td>0.802297</td>\n",
       "      <td>0.805304</td>\n",
       "      <td>0.802297</td>\n",
       "      <td>0.803395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token-char-pos</th>\n",
       "      <td>0.848305</td>\n",
       "      <td>0.849181</td>\n",
       "      <td>0.848305</td>\n",
       "      <td>0.847232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  precision    recall  f1_score\n",
       "baseline        0.721832   0.718647  0.721832  0.698925\n",
       "conv1D-token    0.798292   0.797459  0.798292  0.795295\n",
       "conv1D-char     0.629816   0.645227  0.629816  0.625054\n",
       "token-char      0.802297   0.805304  0.802297  0.803395\n",
       "token-char-pos  0.848305   0.849181  0.848305  0.847232"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'baseline' : baseline_score,\n",
    "    'conv1D-token':model_1_result,\n",
    "    'conv1D-char':model_3_result,\n",
    "    'token-char':model_4_result,\n",
    "    'token-char-pos':model_5_result\n",
    "}).T\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot(kind='bar', figsize=(14,6)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.sort_values('f1_score', ascending=True)['f1_score'].plot(kind='bar', figsize=(12,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribid_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribid_model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000229BA3042E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000229BA3073D0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model_5.save('skimlit_tribid_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x229f03b9210>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('skimlit_tribid_model')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction  = tf.argmax(loaded_model.predict(val_token_char_pos_dataset), axis=1)\n",
    "prediction_result = evaluate_score(val_labels_, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_result == prediction_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e79917a05e390872358bfb73c58bc903ada01d2d04077091749088207d82cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
