{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks and Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '10_food_classes_all_data'\n",
    "train_path = os.path.join(dir_path,'train')\n",
    "test_path = os.path.join(dir_path,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 dir and 0 images >> \"10_food_classes_all_data\"\n",
      "\n",
      "10 dir and 0 images >> \"10_food_classes_all_data\\test\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\chicken_curry\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\chicken_wings\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\fried_rice\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\grilled_salmon\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\hamburger\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\ice_cream\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\pizza\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\ramen\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\steak\"\n",
      "0 dir and 250 images >> \"10_food_classes_all_data\\test\\sushi\"\n",
      "\n",
      "10 dir and 0 images >> \"10_food_classes_all_data\\train\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\chicken_curry\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\chicken_wings\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\fried_rice\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\grilled_salmon\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\hamburger\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\ice_cream\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\pizza\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\ramen\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\steak\"\n",
      "0 dir and 750 images >> \"10_food_classes_all_data\\train\\sushi\"\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    if len(dirnames) != 0 :\n",
    "        print()\n",
    "    print(f'{len(dirnames)} dir and {len(filenames)} images >> \"{dirpath}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#preprocess data (and scaling)\n",
    "train_datagen = ImageDataGenerator(rescale=1/255., rotation_range=.2,shear_range=.2,\n",
    "                                    zoom_range=.2,width_shift_range=.2,\n",
    "                                    height_shift_range=.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "#import data and turn to batches\n",
    "train_data = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                                batch_size=32,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                seed=42)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(directory=test_path,\n",
    "                                                batch_size=32,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                seed=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chicken_curry',\n",
       " 'chicken_wings',\n",
       " 'fried_rice',\n",
       " 'grilled_salmon',\n",
       " 'hamburger',\n",
       " 'ice_cream',\n",
       " 'pizza',\n",
       " 'ramen',\n",
       " 'steak',\n",
       " 'sushi']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(train_data.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 166s 707ms/step - loss: 2.1804 - accuracy: 0.2093 - val_loss: 1.9523 - val_accuracy: 0.3268\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 140s 596ms/step - loss: 2.0494 - accuracy: 0.2733 - val_loss: 1.8537 - val_accuracy: 0.3536\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 137s 583ms/step - loss: 1.9850 - accuracy: 0.3093 - val_loss: 1.8066 - val_accuracy: 0.3792\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 138s 586ms/step - loss: 1.9324 - accuracy: 0.3308 - val_loss: 1.7999 - val_accuracy: 0.3772\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 138s 585ms/step - loss: 1.9148 - accuracy: 0.3345 - val_loss: 1.7391 - val_accuracy: 0.4116\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_1 = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters= 10,kernel_size= (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# because in datagen return onehot in 'categorical' mode\n",
    "model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                optimizer=tf.keras.optimizers.Adam(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history_1 = model_1.fit(train_data, epochs=5, \n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data, \n",
    "                        validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 222, 222, 10)      280       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 111, 111, 10)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 109, 109, 10)      910       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 54, 54, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 29160)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                291610    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 292,800\n",
      "Trainable params: 292,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply from some experience from model_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_1.layers[:-2] :\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 99s 421ms/step - loss: 2.0984 - accuracy: 0.2476 - val_loss: 1.8264 - val_accuracy: 0.3704\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 99s 421ms/step - loss: 1.9207 - accuracy: 0.3357 - val_loss: 1.7928 - val_accuracy: 0.3864\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 99s 421ms/step - loss: 1.8843 - accuracy: 0.3495 - val_loss: 1.7818 - val_accuracy: 0.3764\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 98s 418ms/step - loss: 1.8589 - accuracy: 0.3564 - val_loss: 1.6873 - val_accuracy: 0.4272\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 106s 452ms/step - loss: 1.8441 - accuracy: 0.3688 - val_loss: 1.6756 - val_accuracy: 0.4312\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential([ \n",
    "    model_1.layers[0],\n",
    "    model_1.layers[1],\n",
    "    model_1.layers[2],\n",
    "    model_1.layers[3],\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters= 10,kernel_size= (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                optimizer=tf.keras.optimizers.Adam(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(train_data, epochs=5, \n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data, \n",
    "                        validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 222, 222, 10)      280       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 111, 111, 10)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 109, 109, 10)      910       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 54, 54, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 52, 52, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 26, 26, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 6760)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                67610     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,710\n",
      "Trainable params: 68,520\n",
      "Non-trainable params: 1,190\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 9s 115ms/step - loss: 1.7391 - accuracy: 0.4116\n",
      "[1.7391011714935303, 0.4115999937057495]\n",
      "79/79 [==============================] - 9s 116ms/step - loss: 1.6756 - accuracy: 0.4312\n",
      "[1.6755839586257935, 0.4311999976634979]\n"
     ]
    }
   ],
   "source": [
    "print(model_1.evaluate(test_data))\n",
    "print(model_2.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> slightly improve accuracy."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63e79917a05e390872358bfb73c58bc903ada01d2d04077091749088207d82cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
